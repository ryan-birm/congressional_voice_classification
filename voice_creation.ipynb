{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pip Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install librosa\n",
    "!pip install tensorflow\n",
    "!pip install numpy==1.23.5\n",
    "!pip install pysoundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor flow does not work with Numpy 2.0 onward so make sure that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from pydub import AudioSegment as audio\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "#Tensor Flow needs numpy at 1.23.5\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import re \n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data_dir = os.path.abspath('') + \"/Unprocessed_Wav_Files\"\n",
    "proccesed_data_dir = os.path.abspath('') + \"/Processed_Wav_Files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "- go through all files in the unprocessed wav files\n",
    "- break up all files so they are split by 1 second\n",
    "- use regex to get the file name minus the .wav at the end to make new 1 second wav files\n",
    "- save each of the files into the processed wav folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample the unproccessed audio files for speaker recognition. This is needed for tensorflow and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf_path = os.path.join(unproccessed_data_dir, \"addisonWilson40173Clip1.wav\")\\narr, hz = librosa.load(f_path, sr = None)\\nnew_f = librosa.resample(arr, orig_sr= hz, target_sr= 16000)\\nsf.write(os.path.join(unproccessed_data_dir,\"new.wav\"),new_f, 16000)\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This was a test for the fixing the audio with a single thing\n",
    "\n",
    "\"\"\"\n",
    "f_path = os.path.join(unproccessed_data_dir, \"addisonWilson40173Clip1.wav\")\n",
    "arr, hz = librosa.load(f_path, sr = None)\n",
    "new_f = librosa.resample(arr, orig_sr= hz, target_sr= 16000)\n",
    "sf.write(os.path.join(unproccessed_data_dir,\"new.wav\"),new_f, 16000)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes the Unporcessed_Wav_Files into 16000 hz\n",
    "\n",
    "This is necessary for speaker recognition model training and feature extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(unprocessed_data_dir):\n",
    "    f_path = os.path.join(unprocessed_data_dir, file)\n",
    "    arr, hz = librosa.load(f_path,sr = None)\n",
    "    if hz != 16000:\n",
    "        new_f = librosa.resample(arr, orig_sr = hz, target_sr = 16000)\n",
    "        sf.write(f_path, new_f, 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "f_path = os.path.join(unprocessed_data_dir, \"addisonWilson40173Clip1.wav\")\n",
    "arr, hz = librosa.load(f_path, sr = None)\n",
    "print(hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separates the files into 1 second intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(unprocessed_data_dir):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        hearing = audio.from_wav(os.path.join(unprocessed_data_dir,filename))\n",
    "        speaker = filename.removesuffix(\".wav\")\n",
    "        #name of congress person for processed_wav_files folder\n",
    "        congress_name = speaker[:re.search(r\"\\d+\",speaker).start()] \n",
    "        #start duration in milliseconds for audio recording start\n",
    "        t1 = 0\n",
    "        #end duration in milliseconds for audio recording start\n",
    "        t2 = 1000\n",
    "        #second of the clip\n",
    "        second = 1\n",
    "        total_time = hearing.duration_seconds*1000\n",
    "        # Goes through all of the large audio files, splits them into 1 second audio files\n",
    "        # and saves to the speaker name folder\n",
    "        while t2 <= total_time:\n",
    "            new_audio = hearing[t1:t2]\n",
    "            #arr, hz = librosa.load(new_audio, sr = None)\n",
    "            try:\n",
    "                os.makedirs(f\"{proccesed_data_dir}/{congress_name}\")\n",
    "                new_audio.export(f\"{proccesed_data_dir}/{congress_name}/{speaker}_{second}.wav\", format = \"wav\");\n",
    "                #new_audio.export(f\"{proccesed_data_dir}/{congress_name}/{speaker}_{second}.wav\", format = \"wav\", parameters=[\"-ar\", \"16000\"]);\n",
    "            except:\n",
    "                #new_audio.export(f\"{proccesed_data_dir}/{congress_name}/{speaker}_{second}.wav\", format = \"wav\", parameters=[\"-ar\", \"16000\"]);\n",
    "                new_audio.export(f\"{proccesed_data_dir}/{congress_name}/{speaker}_{second}.wav\", format = \"wav\");\n",
    "            t1 += 1000\n",
    "            t2 += 1000\n",
    "            second += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Hz of a split file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "a,b = librosa.load(os.path.abspath('')  + \"/Processed_Wav_Files/addisonWilson/addisonWilson40173Clip1_2.wav\", sr = None)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract (data_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for foldr in os.listdir(data_dir):\n",
    "        if foldr != \".DS_Store\":\n",
    "            for file in os.listdir(f\"{data_dir}/{foldr}\"):\n",
    "                arr, hz = librosa.load(os.path.join(data_dir,foldr,file), sr = None, duration =  1)\n",
    "                mfccs = librosa.feature.mfcc(y = arr, sr = hz, n_mfcc = 13)\n",
    "                mfccs = StandardScaler().fit_transform(mfccs)\n",
    "                features.append(mfccs.T)\n",
    "                labels.append(foldr)       \n",
    "    return np.array(features), np.array(labels)           \n",
    "features, labels = feature_extract(proccesed_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature_set, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(features, (x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Features Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_set\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(feature_set)  \u001b[38;5;66;03m# Optionally print the actual features\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for feature_set, label in zip(features, (x for x in len(labels) if x%100 == 0)):\n",
    "    print(f\"Label: {label}, Features Shape: {feature_set.shape}\")\n",
    "    print(feature_set)  # Optionally print the actual features\n",
    "    print(\"-\" * 40)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
